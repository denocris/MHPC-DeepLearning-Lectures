{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "appendix_A_tf_low-level-api_basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LlW23hvToHkg",
        "jr69rTaloHki",
        "wCjqMRVyoHlg",
        "oTegqMbqoHmA",
        "qN-UQLdBoHmT",
        "qvP0RR4OoHnH",
        "9QnwS5SEoHn0",
        "Q2CycjRgoHoJ",
        "fkPcHjqzoHoL",
        "tPvDuJGPoHoe"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denocris/MHPC-DeepLearning-Lectures/blob/master/appendix_A_tf_low_level_api_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dlMr9HroHkP",
        "colab_type": "text"
      },
      "source": [
        "<h1 style=\"text-align: center;\" markdown=\"1\"> Tensorflow Basic Concepts </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSa1_pGFoHkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mz_-pxUoHkZ",
        "colab_type": "code",
        "outputId": "06af9818-6ebb-434b-a9c5-a326173691b0",
        "colab": {}
      },
      "source": [
        "import bokeh.plotting as bk\n",
        "bk.output_notebook()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div class=\"bk-root\">\n",
              "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
              "        <span id=\"1001\">Loading BokehJS ...</span>\n",
              "    </div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(\"1001\");\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };var element = document.getElementById(\"1001\");\n",
              "  if (element == null) {\n",
              "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
              "    return false;\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }if (force === true) {\n",
              "        display_loaded();\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlW23hvToHkg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3-QlHwoHkh",
        "colab_type": "text"
      },
      "source": [
        "### Why TensorFlow?\n",
        "\n",
        "*“While the mathematical concepts behind deep learning have been around for decades,\n",
        "programming libraries dedicated to creating and training these deep models have only been\n",
        "available in recent years.\n",
        "Unfortunately, most of these libraries have a large trade off between **flexibility** and\n",
        "**production-worthiness (scalability)**. Flexible libraries are invaluable for researching novel model\n",
        "architectures, but are often either too slow or incapable of being used in production (PyTorch). On the\n",
        "other hand, fast, efficient, libraries which can be hosted on distributed hardware are available,\n",
        "but they often specialize in specific types of neural networks and aren’t suited to researching\n",
        "new and better models (Caffe). This leaves decision makers with a dilemma: should we attempt to do\n",
        "research with inflexible libraries so that we don’t have to reimplement code, or should we use\n",
        "one library for research and a completely different library for production? If we choose the\n",
        "former, we may be unable to test out different types of neural network models; if we choose the\n",
        "latter, we have to maintain code that may have completely di erent APIs. Do we even have the\n",
        "resources for this?\n",
        "TensorFlow aim s to solve this dilemma. Tensorflow is both **flexible** and **scalable** and allows users to go easility from research into production.”* Ariel Scarpinelli, Erik Erwitt, Danijar Hafner, Troy Mott, Sam Abrahams in TensorFlow for Machine Intelligence.\n",
        "\n",
        "\n",
        "In TensorFlow the computation is formally a **graph**\n",
        "\n",
        "- with **nodes** representing operations;\n",
        "- while **edges** representing tensors (multidimensional data) communicated between operations. \n",
        "\n",
        "It is not intended to be only a neural network library but to perform any computation that can be expressed as a graph. TensorFlow automatic differentiation is especially suited for gradient based machine learning algorithms. The library is written in C++ and it has nice Python bindings. Moreover it can run both on CPU and GPU. \n",
        "\n",
        "\n",
        "<!---\n",
        "For more information please visit [TensorFlow](http://www.tensorflow.org).\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr69rTaloHki",
        "colab_type": "text"
      },
      "source": [
        "## 2 Tensorflow Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssbf11JHoHki",
        "colab_type": "text"
      },
      "source": [
        "First import tensorflow and show current version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZduO9b9oHkj",
        "colab_type": "code",
        "outputId": "3ba8e0b8-461d-4a83-ea34-e51898a9a53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22P-HVEroHko",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow represent computations as **graphs**. Nodes in the graph are called **ops** (operations). An op takes zero or more **Tensors** and produces zero or more Tensors as output. A Tensor is a multidimensional array with a specified type. The graph is a description of a computation, in order to actually execute the computation a graph must be launched in a **session**. A session execute a specific graph on one of the available **devices** (that can be either CPUs or GPUs).\n",
        "\n",
        "In following paragraphs we will clarify these concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZrazVZoHkp",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Computation Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqdmMgYXoHkq",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow programs are usually structured as follows:\n",
        "\n",
        "- a **construction phase**, that assembles a **graph**;\n",
        "- an **execution phase** that uses a **session** to execute ops in the graph.\n",
        "\n",
        "It is possibile to build a graph by starting with nodes that do not need any input, such as constant nodes. Then it is possible to use the output of the constant node as input to other operations. TensorFlow uses a default graph to which operations are added, the default graph is created empty as soon as tensorflow is imported. It is sufficient for most operations but it is also possible to manage multiple graphs with the `Graph` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgWfqH2yoHkr",
        "colab_type": "text"
      },
      "source": [
        "Let's first perform a simple operation in **Numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QVKr2mEoHks",
        "colab_type": "code",
        "outputId": "b4a9325e-6d40-48ce-f9e6-808635cf9fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = 4.\n",
        "y = 3.\n",
        "numpy_prod = np.multiply(x, y)\n",
        "\n",
        "print(numpy_prod)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKvrlnToHkw",
        "colab_type": "text"
      },
      "source": [
        "Let's try the same op in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67X9IqBXoHkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.constant(4.)\n",
        "y = tf.constant(3.)\n",
        "\n",
        "# for later use let's also define \n",
        "p = tf.placeholder(tf.float32, shape=())\n",
        "\n",
        "product = tf.multiply(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9iknrtLoHk0",
        "colab_type": "text"
      },
      "source": [
        "The code creates three nodes: two constant and an operation (multiplication) that takes two inputs (the two constants) and produces an output (product). To actually procude an output is is necessary to run the graph in a session. \n",
        "\n",
        "What is the difference between this expression and a corresponding plain python code that multiply two constants? Try to print the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMtbn2Q-oHk1",
        "colab_type": "code",
        "outputId": "8ef4598b-0261-4f13-baca-e038b735a844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(product)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mul:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0rIhsw_oHk4",
        "colab_type": "text"
      },
      "source": [
        "The key idea is that `product` **does not compute the product of x and y but rather add the product operator to a graph of computation that will be executed later**. The most striking difference between TensorFlow and other numerical computation libraries such as NumPy is that **operations in TensorFlow are symbolic**.\n",
        "\n",
        "**Computation Graphs** allow us to implement ML algorithms by creating and executing operations that interacts with each others. The interaction between operations constitutes the graph. \n",
        "\n",
        "What is a graph in the end? It is a set of *nodes* (or vertices) interconnected by (directed) *edges*. Edges allow data to **flow** from one node to another. Each node represent an operation, that produces an ouput that is passed on in the graph. Operations can be of any kind, from math to logging operation (we will se more on this when we will use TensorBoard).\n",
        "\n",
        "The graph connectivity defines a set of node dependencies, TensorFlow is able to optimize the computation based on this dependencies. Being able to identify connectivities allows to distribute computation and avoid performing redundant computations on irrelevant portion of the graph.\n",
        "\n",
        "We can add other operations to the graph. For example we can do a sum after the product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5GTW1dKoHk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = tf.constant(8.)\n",
        "addition = tf.add(product, z)\n",
        "\n",
        "addition_with_p = tf.add(product, p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n8oGgu8oHk9",
        "colab_type": "text"
      },
      "source": [
        "The next image represent the default graph for the operations defined before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7D0Hmv61AGl",
        "colab_type": "text"
      },
      "source": [
        "<center>  <img src=https://drive.google.com/uc?id=1uKqDbnwF7nbzdkBiQ24N1akbD51wchCy \" width=\"700\">  </center> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBpN-PMroHlC",
        "colab_type": "text"
      },
      "source": [
        "Remember that the name of the variables (x, y and product) should be regarded **as the output of the operations and not the opration themselves**. Note that for some arithmetic and logical operation it is possible to use operator overloading instead of using `tf.<operator>`. For example the multiplication could be written `product = x * y`.\n",
        "\n",
        "It is possible to create additional graphs and control how operations and variables get associated with them. `tf.Graph()` creates a new graph. To check which graph is currently se as default we use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIWmXOXNoHlD",
        "colab_type": "code",
        "outputId": "0c8f807d-24d1-4ab6-d4ba-0bd361be0236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "g_default = tf.get_default_graph()\n",
        "print(g_default)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.framework.ops.Graph object at 0x7f8fcb3b13c8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwbaanBWoHlI",
        "colab_type": "text"
      },
      "source": [
        "Now we create a new graph g."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLKaigMsoHlK",
        "colab_type": "code",
        "outputId": "17aea770-d705-459a-a30f-8f6abe5e2d09",
        "colab": {}
      },
      "source": [
        "g = tf.Graph()\n",
        "print(g)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.framework.ops.Graph object at 0x1259731d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJOSGUbPoHlO",
        "colab_type": "text"
      },
      "source": [
        "As you can see they are diffrent objects. Also, given a node, we can see to which graph is associated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irzH39KKoHlQ",
        "colab_type": "code",
        "outputId": "d417d1c6-4493-48d9-a377-0c8f049d73e1",
        "colab": {}
      },
      "source": [
        "print(x.graph is g)\n",
        "print(x.graph is g_default)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xzA7gZWoHlV",
        "colab_type": "text"
      },
      "source": [
        "Using `with` statement we can control which graph is set as default and add new nodes to it. For example we can do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD8hTwZXoHlW",
        "colab_type": "code",
        "outputId": "0b353d77-f251-4bf7-a0d5-f7acb4b92eea",
        "colab": {}
      },
      "source": [
        "print(g is tf.get_default_graph())\n",
        "\n",
        "with g.as_default():\n",
        "    print(g is tf.get_default_graph())\n",
        "    \n",
        "print(g_default is tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvqiFktOoHle",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow uses graphs as an abstraction for various reasons. The main reason is that Neural Networks have a natural graph structure. Moreover graphs can split computation into small differentiable pieces, that allows TensorFlow to compute derivative of any node w.r.t. any other node in the graph. Neural Network learning algorithm is based on gradients. Finally having the computation separated makes it much easier to distribute work across multiple CPUs, GPUs, and other computational devices. (There is one more reason that we will see briefly: save computation, only runnig subgraphs that are connected to the value to fetch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCjqMRVyoHlg",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rof8WDa4oHlg",
        "colab_type": "text"
      },
      "source": [
        "Once the computation graph is defined we can use it in a **Session** to actually obtain the result. Session objects are part of TensorFlow API that are responsible for the communication between data and objects and compuational resources. The computation is performed with the method `run()` of the session object. Without arguments `Session` uses the default graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXRiS_QHoHlh",
        "colab_type": "code",
        "outputId": "1d581151-c905-4d10-bb86-c25ed3899b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "result = sess.run([addition])\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U34nXI5AoHlk",
        "colab_type": "text"
      },
      "source": [
        "It is necessary to close a session after last operation, to release computational resources; closing a session is done with the method `close()`. It is possible to use `with ... as  ...` statement, that takes care of releasing resources when computation is finished.\n",
        "\n",
        "Tensorflow translates the graph into executable operations and it distributes the computation automatically on available resources. It uses the available **GPU** for as many operations as possible.\n",
        "\n",
        "It is possible to use a **specific device** for a session with `with tf.device(\"/gpu:1\"):` statement. For example previous command execute the graph on the second GPU of the machine. Try to change the string and execute the code on CPU (or another GPU of your machine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlueg4WLoHlm",
        "colab_type": "code",
        "outputId": "7e23a022-6392-436d-ff1c-5f02ece807ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    with tf.device(\"/cpu:0\"): # optional\n",
        "        result = sess.run([addition])\n",
        "        print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXg9eh87oHlp",
        "colab_type": "text"
      },
      "source": [
        "In the these example we requested a particular node of the graph, by passing it to the method `run()`. This is called **fetch** and the arguments of the function are the fetches. It is possible to fetch more than one variable by passing them simultaneously to the run() command (`session.run([var1, var2])`). The result is a list of values fetched. \n",
        "\n",
        "As we said earlier, TensorFlow computes only the necessary portion of the graph if we ask to compute only the product, only the output of node product is computed (involving only the nodes to which it depends)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWSpxasxoHlq",
        "colab_type": "code",
        "outputId": "d0ef2e8e-636e-4443-b3f8-73c1c9d81eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    result = sess.run([product, addition])\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12.0, 20.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMeaZi_sz2p",
        "colab_type": "code",
        "outputId": "4c949393-8dfc-476e-8d99-3faad1425531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    result = sess.run([product, addition, addition_with_p], feed_dict={p: 7.0})\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12.0, 20.0, 19.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuvyCZlaoHlw",
        "colab_type": "text"
      },
      "source": [
        "In an interactive environment like IPython or Jupyter it could be useful to interleave graph construction and run operations, you can use `InteractiveSession`. The only difference with a regular `Session` is that an `InteractiveSession` installs itself as the default session on construction. The methods `Tensor.eval()` and `Operation.run()` will use that session to run ops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zM3nOgoHlx",
        "colab_type": "code",
        "outputId": "c916862d-bb23-45ab-b321-dce8e286fbf9",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "c = tf.linspace(0.0, 1.0, 5)\n",
        "print(c.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.   0.25 0.5  0.75 1.  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQxVIcNgoHl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = tf.get_default_graph()\n",
        "operations = [op for op in g.get_operations()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qh1VwBoHl3",
        "colab_type": "code",
        "outputId": "2c0fd654-59b7-4d4e-92a2-d8c1f31de33e",
        "colab": {}
      },
      "source": [
        "[op.name for op in operations]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Const',\n",
              " 'Const_1',\n",
              " 'Mul',\n",
              " 'Const_2',\n",
              " 'Const_3',\n",
              " 'Mul_1',\n",
              " 'Const_4',\n",
              " 'Const_5',\n",
              " 'Mul_2',\n",
              " 'Const_6',\n",
              " 'Add',\n",
              " 'LinSpace/start',\n",
              " 'LinSpace/stop',\n",
              " 'LinSpace/num',\n",
              " 'LinSpace']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bqkDqBoHl7",
        "colab_type": "text"
      },
      "source": [
        "Running an operation makes tensorflow running all the operations required for the input of this operation, but doesn't return anything. It is also possible to get tensors and operations by name from a graph. \n",
        "\n",
        "Now we close interactive session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIxXjA0doHl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvQshX60oHl-",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** the session runs the default graph. Using multiple graphs is generally avoided, each graph will require a separate sessions and each session tend to use all available resources. Moreover passing data between them is a bottleneck because usually require using python/numpy and does not work in a distributed environment. It is better to have a disconnected subgraph within the default graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdoj3vvWoHmA",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMIBwJ4roHmA",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow uses **Tensors** to represents all data. Only tensors are passed between ops in the graph. Tensors are an n-dimensional arrays, and, in TensorFlow, are described with rank, shape and type. The rank its the number of dimensions (different from matrix rank), the shape is the number of elements for each dimension and the type is the data type assigned to the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTegqMbqoHmA",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3.1 Tensors as results of Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbJBdtVoHmC",
        "colab_type": "text"
      },
      "source": [
        "When we create an operation for example with tf.add(), the operation is a *node* added to the graph but the handle we get is the tensor that results from the operation. This handle is the *edge* of the graph and it passes (**flow**) the yet-to-be-computed result of the operation to other nodes.\n",
        "\n",
        "Tensors objects have attributes and operations. For example the tensor `x` is a tensor with no shape (actually shape 1x1) that is a scalar, and it's dtype is a float32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R5G8uw1oHmC",
        "colab_type": "code",
        "outputId": "7c0adb5b-a939-4973-9880-e5497dca8e9c",
        "colab": {}
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V95anW4aoHmF",
        "colab_type": "text"
      },
      "source": [
        "Tensors dtype can be specified at creation time or can be modified later using `tf.cast` operation. Tensor can be viewed as n-dimensional arrays. As we have already seen a $1 \\times 1$ tensor is a scalar, a $1 \\times n$ tensor is a vector, a $n \\times n$ tensor is a matrix, a $n \\times n \\times n$ tensor is a three dimensional array, and so on (it can be generalized to any dimension). As with dtypes, TensorFlow can infer automatically the dimension of a tensor object given the shape of the data. For example if we want to create a matrix with `tf.constant` and see what shape we get, we can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHYiO5LoHmF",
        "colab_type": "code",
        "outputId": "fca2c0e4-13dc-44e6-8f54-046b7c0aadd5",
        "colab": {}
      },
      "source": [
        "w = tf.constant([[1,2,3], \n",
        "                 [4,5,6]])\n",
        "print(w.get_shape())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwianuP-oHmK",
        "colab_type": "text"
      },
      "source": [
        "Other types of operations that generates number without user input are random number generation operators, linspace (as seen before), array of constant (one or zero values) and many others. They resemble the operations and API used by numpy. \n",
        "\n",
        "An important operation that we will use often is matrix multiplication. It is needed to perform operations like $Ax=b$, where $A$ is a matrix and $x$ is a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_hkdIlUoHmL",
        "colab_type": "code",
        "outputId": "ba7e5598-4942-4d31-adc7-dd37f4fc85ce",
        "colab": {}
      },
      "source": [
        "A = tf.constant([[1,2,3],\n",
        "                 [4,5,6]])\n",
        "print(A.get_shape())\n",
        "x = tf.constant([[1],[0],[1]])\n",
        "print(x.get_shape())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "(3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldg6kbncoHmO",
        "colab_type": "code",
        "outputId": "a4295227-9cfe-4b57-f974-c305d5b653ce",
        "colab": {}
      },
      "source": [
        "b = tf.matmul(A, x)\n",
        "with tf.Session() as sess:\n",
        "    print(b.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4]\n",
            " [10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqHqEpo-oHmR",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** if you experience warnings, it means TensorFlow wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations. To suppress them use: \n",
        "\n",
        ">`import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN-UQLdBoHmT",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3.2 Names and Scopes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMmYLy0ooHmT",
        "colab_type": "text"
      },
      "source": [
        "Tensors have a **name** as well, it can be assigned at creation time or TensorFlow assign it for  you (as happened before). It can be displayed with method `name`. The name of the objec is simply the name of the operation followed by a colon and the index of that tensor in the output of the operation that produced it. If two or more operations exists, tensorflow add an underscore to its names followed by a progressive number to avoid tensors with the same name. In following code we will specify the name of the operation at construction time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsuQ7pwKoHmU",
        "colab_type": "code",
        "outputId": "d52613d9-d983-4407-8a75-09fad1615f64",
        "colab": {}
      },
      "source": [
        "b.name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MatMul:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJu3dl2FoHmX",
        "colab_type": "text"
      },
      "source": [
        "Sometimes can be useful, especially in complicated graphs, to group together related tensors, that belong to a certain portion of the graph for example. **Name scopes** are used for this purpose. Here's an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4IQMbPmoHmY",
        "colab_type": "code",
        "outputId": "249cda31-75cc-43e4-8465-37870f994522",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    a1 = tf.constant(4, dtype=tf.float64, name='variable_a1')\n",
        "    with tf.name_scope(\"group\"):\n",
        "        group_a1 = tf.constant(4,dtype=tf.int32, name='variable_a1')\n",
        "        group_a2 = tf.constant(4,dtype=tf.int32, name='variable_a2')\n",
        "\n",
        "print(a1.name)\n",
        "print(group_a1.name)\n",
        "print(group_a2.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "variable_a1:0\n",
            "group/variable_a1:0\n",
            "group/variable_a2:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AghFqDqoHmb",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow provides an interface similar to numpy, for example it implements broadcasting. Note that `a` is a list with 2 elements while `b` is a matrix 2 by 2. `a` is broadcasted (repeated) to match the shape of `b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zEN5IDsoHmc",
        "colab_type": "code",
        "outputId": "38763f22-7696-4643-f86b-573e499bc190",
        "colab": {}
      },
      "source": [
        "a = tf.constant([2, 2], name='a')\n",
        "b = tf.constant([[0, 1], [2, 3]], name='b')\n",
        "x = tf.multiply(a, b, name='mul')\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [4 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRUeGIKkoHmi",
        "colab_type": "text"
      },
      "source": [
        "Like numpy TensorFlow provides a way to create tensors filled with specific values. Next example create a tensor of shape (2, 3) filled with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHJll4MyoHmk",
        "colab_type": "code",
        "outputId": "3b085fb8-9648-48d1-e7ec-5ccebf2a5ee8",
        "colab": {}
      },
      "source": [
        "zeros = tf.zeros([2, 3], tf.int32, name='zeros')\n",
        "#zeros = tf.identity(zeros, name='add_zeros')\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(zeros))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0]\n",
            " [0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXY0w39DoHmn",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to create a tensor with same shape and type of an existing tensor, for example we can create a tensor similar to the previous but filled with ones this time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1q2RUwJoHmo",
        "colab_type": "code",
        "outputId": "a5b99477-b851-4dc9-9fe7-45f5a00f76eb",
        "colab": {}
      },
      "source": [
        "ones_like = tf.ones_like(zeros, name='ones')\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(ones_like))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1]\n",
            " [1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoH_74ecoHmr",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to use a specific value to fill the tensor with.\n",
        "\n",
        "Next we will create a constant tensor, but this time it will have a sequence of values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfSitcopoHmt",
        "colab_type": "code",
        "outputId": "8d0da0f8-4ff0-444f-f7ff-f021a10e684d",
        "colab": {}
      },
      "source": [
        "lin_space = tf.lin_space(10.0, 13.0, 4, name='linspace_example')\n",
        "ran_ge = tf.range(5, name='range_example') \n",
        "with tf.Session() as sess:\n",
        "    print('lin_space: ', sess.run(lin_space))\n",
        "    print('range: ', sess.run(ran_ge))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lin_space:  [10. 11. 12. 13.]\n",
            "range:  [0 1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmqCFw-7oHmw",
        "colab_type": "text"
      },
      "source": [
        "What if we want to generate random number? (We will see it is specially usefull for initialize Neural Networks weights). For example we can sample number from a normal distribution or a truncated normal, that doesn't return any values more than two standard deviations away from its mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JCKd4vRoHmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truncated_normal = tf.truncated_normal((10000,))\n",
        "with tf.Session() as sess:\n",
        "    values = sess.run(truncated_normal)\n",
        "hist, edges = np.histogram(values, density=True, bins=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBMncqSNoHm1",
        "colab_type": "code",
        "outputId": "aa1cf95d-7a32-49e2-e942-9c9618f4e3c3",
        "colab": {}
      },
      "source": [
        "plt.hist(hist, 20, facecolor='g', alpha=0.75)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x126a96ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnIBNJcaoHm4",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow offers a series of **operations** similar to numpy, for example: `tf.abs, tf.negative, tf.sqrt, tf.exp` and so on. It also has operations for arrays, `tf.concat, tf.split, tf.shape` and for control flow, checkpointing and Neural Networks building blocks. We will see them in following notebooks and we will describe them when needed (most of them are self-explanatory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8fii_YGoHm5",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow supports native python data types, if you pass a list or numpy array to a constant function like one of the above, the resulting tensor will have corresponding data type. Single values will be converted to 0 dimensional tensors (scalars), lists will be converted to one dimensional tensors (vectors), nested lists will be converted to two dimensional tensors (matrices) and so forth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6nBUcQPoHm8",
        "colab_type": "code",
        "outputId": "9dc2d2e7-c51a-48e5-e9ed-3c7d9807ae50",
        "colab": {}
      },
      "source": [
        "tensor_d0 = tf.constant(42, name='scalar')\n",
        "tensor_d1 = tf.constant([42, 42], name='vector')\n",
        "tensor_d2 = tf.constant([[42], [42]], name='matrix')\n",
        "with tf.Session() as sess:\n",
        "    print(tensor_d0.eval())\n",
        "    print(tensor_d1.eval())\n",
        "    print(tensor_d2.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n",
            "[42 42]\n",
            "[[42]\n",
            " [42]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6QBbPZoHm-",
        "colab_type": "text"
      },
      "source": [
        "But tensorflow has its own data types, for example `tf.int8` or `tf.float16`. TensorFlow integrates seamlessly with NumPy types, and as we have seen it is possible to pass numpy types to TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm7TfpTyoHnA",
        "colab_type": "code",
        "outputId": "13c3124f-6520-4a08-f432-1c56f6bf5d35",
        "colab": {}
      },
      "source": [
        "tf.int32 == np.int32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws4LcxyCoHnD",
        "colab_type": "text"
      },
      "source": [
        "As we have seen using python types to specify TensorFlow type is easy, and it is useful for quick prototyping. However TensorFlow types are more specific, for examples pyhton has one integer type only whereas TensorFlow has more int-8 to int-64. For bigger projects it is preferable to use native TensorFlow types.\n",
        "\n",
        "Aside from the fact that costants are, well, constant, there is one more caveats to their use: constants are stored in the **graph definition**. The graph definition is stored in a protobuf, protocol buffers, Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te6pdVXloHnE",
        "colab_type": "code",
        "outputId": "adc9b1ae-dcff-470d-f439-900d2fda09d2",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    const_value = tf.constant([42.0, 42.0], name=\"const_value\")\n",
        "    with tf.Session() as sess:\n",
        "        print(sess.graph.as_graph_def())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node {\n",
            "  name: \"const_value\"\n",
            "  op: \"Const\"\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"value\"\n",
            "    value {\n",
            "      tensor {\n",
            "        dtype: DT_FLOAT\n",
            "        tensor_shape {\n",
            "          dim {\n",
            "            size: 2\n",
            "          }\n",
            "        }\n",
            "        tensor_content: \"\\000\\000(B\\000\\000(B\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "versions {\n",
            "  producer: 26\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoeDUVfCoHnG",
        "colab_type": "text"
      },
      "source": [
        "This makes loading graphs expensive when constants are big, and could reach the limit of 2GB for the size of the graph. It is better to use constants only for primitive types. \n",
        "\n",
        "For these reasons we introduce variables next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvP0RR4OoHnH",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3.3 Variables and Placeholders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Xbqc1AoHnI",
        "colab_type": "text"
      },
      "source": [
        "**Variables** are used to maintain state accross executions of the graph. In this example `state` is initialized to zero and updated each time `update` is run. When using variables, they **must be initialized** after launching the graph, that is after creating a session. In order to initialize the variables it is necessary to add an init operation that must be run *before* all other operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tiR8uY8oHnI",
        "colab_type": "code",
        "outputId": "fae7ec6f-6aaf-4beb-fb49-f6d5bf12afb6",
        "colab": {}
      },
      "source": [
        "state = tf.Variable(0, name='counter')\n",
        "\n",
        "one = tf.constant(1, name='one')\n",
        "new_value = tf.add(state, one, name='new_value')\n",
        "update = tf.assign(state, new_value, name='update')\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "    print('state: ' + str(sess.run(state)))\n",
        "    for _ in range(5):\n",
        "        sess.run(update)\n",
        "        print('state: ' + str(sess.run(state)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state: 0\n",
            "state: 1\n",
            "state: 2\n",
            "state: 3\n",
            "state: 4\n",
            "state: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsNVjEfxoHnM",
        "colab_type": "text"
      },
      "source": [
        "Here `assign` is part of the computational graph as `add` and other operators. **Variables are typically used to represent parameters of a model**, for example in neural network they are used to store the weights matrix, that it is updated at every execution of the graph. Parameters are updated by the operations in the graph as the result of the optimization process. \n",
        "\n",
        "A Variable exists outside the context of a `session.run`. Variables can be initialized to random values, using a distribution (in the previous example it was initialized to zero). For example we can use a random normal distribution with given mean and standard deviation, as well as specify resulting shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvcYuMk-oHnN",
        "colab_type": "code",
        "outputId": "5d70750b-29b5-4dc5-8e52-bf77954eeca0",
        "colab": {}
      },
      "source": [
        "init_val = tf.random_normal((1, 5), 0, 1, name='init_val')\n",
        "var = tf.Variable(init_val, name='var')\n",
        "print('tensor object: {}'.format(var))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    initialized_values = sess.run(var)\n",
        "    \n",
        "print('tensor values after init: {}'.format(initialized_values))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor object: <tf.Variable 'var_5:0' shape=(1, 5) dtype=float32_ref>\n",
            "tensor values after init: [[-1.2087451   1.6465131   1.0252233  -0.82393837 -0.28529078]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83xC-6wUoHnP",
        "colab_type": "text"
      },
      "source": [
        "Note that if we run the code several times the output changes, but also the object changes (look at the name of the object!). **A new variable is created every time `tf.Variable` method is called.**\n",
        "\n",
        "A better approach would be to **reuse the variable already created.** There are two main approach: pass the variable object around, or encapsulate variable object inside a **variable scope**. As stated in the documentation of TensorFlow, passing variables around is more explicit, but it is sometimes convenient to write TensorFlow functions that implicitly use variables in their implementation. In general using `tf.Variable` directly is discouraged. The preferred method is to use `tf.get_variable`, that allows also to reuse a variable multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZgzx9F5oHnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def var_reuse():\n",
        "    with tf.variable_scope(\"reuse_example\", reuse=tf.AUTO_REUSE):\n",
        "        new_var = tf.get_variable(\"new_var\", initializer=init_val)\n",
        "    return new_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRJ0BZCpoHnT",
        "colab_type": "text"
      },
      "source": [
        "Previous function defines the scope in which variable is declared and it allows you to create a hierachy of definitions (suitable for example for Neural Networks). The parameter `reuse=tf.AUTO_REUSE` tells TensorFlow to create a variable the first time it is called or to reuse an existing one ater."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWEy2qsqoHnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_var1 = var_reuse()  # Creates new_var.\n",
        "new_var2 = var_reuse()  # Gets the same, existing new_var.\n",
        "assert new_var1 == new_var2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkcgNe72oHnW",
        "colab_type": "text"
      },
      "source": [
        "Both `variable_scope` and `name_scope` have the same effect on all operations as well as variables created using tf.Variable (the scope will be added as a prefix to the operation or variable name). However, name scope is **ignored** by tf.get_variable.\n",
        "\n",
        "Each *session* maintains its **own copy** of the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2KEMBrOoHnW",
        "colab_type": "code",
        "outputId": "a3c8c038-8e2f-49d4-eb77-9ae2849dcb88",
        "colab": {}
      },
      "source": [
        "new_var = var_reuse()\n",
        "print('tensor object: {}'.format(new_var))\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.variables_initializer([new_var], name='new_var_init'))\n",
        "    initialized_values = sess.run(new_var)\n",
        "    \n",
        "print('tensor values after init: {}'.format(initialized_values))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor object: <tf.Variable 'reuse_example/new_var:0' shape=(1, 5) dtype=float32_ref>\n",
            "tensor values after init: [[ 0.46264398 -1.1184399   0.39203706 -0.25184998 -0.3591106 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUfO3JfuoHnZ",
        "colab_type": "text"
      },
      "source": [
        "So far we have covered how to store values in constant and use variable to update their values (these operations are called *source* operations). Remember that a the worklfow of a TensorFlow program has two phases: assemble the graph and use a session to execute operations in the graph. **We need a method to assemble the graph without knowing the values for some tensors needed for computation (simply the inputs of our model).**\n",
        "\n",
        "TensorFlow provides a method to pass values to the variables with a **feed** mechanism. A feed replace the value of a tensor with the value that you provide. Tensorflow provides a special structure called **placeholder** for feeding input values. Placeholders have an optional shape parameter, that can be set to `None` meaning that **the shape can be of any size** (we will see that it is common for mini-batches later on). To feed the values we construct a dictionary whose keys correspond to placeholder variables and values can be list or numpy arrays to feed to each variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGnFDJWHoHna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input1 = tf.placeholder(tf.float32, name='input1')\n",
        "input2 = tf.placeholder(tf.float32, name='input2')\n",
        "output = input1 * input2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsank2y9oHnc",
        "colab_type": "text"
      },
      "source": [
        "One caveat of using operator overloading, is that you cannot assign a name to the operation, because a tf.Operation (or tf.Tensor) is immutable once it has been created. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3lNT7W9oHnd",
        "colab_type": "code",
        "outputId": "57bba55c-d37a-45c8-8612-e15900f848b1",
        "colab": {}
      },
      "source": [
        "print(output.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mul:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htn9blRooHnh",
        "colab_type": "text"
      },
      "source": [
        "The typical way to rename an op is therefore to use tf.identity(), which has almost no runtime cost:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPNgBiDoHni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = tf.identity(output, name='placeholder_multiplication')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5D_wuvGoHnj",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** the recommended way to structure a name scope is to assign the name of the scope itself to the output from the scope (if there is a single output op):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvVbMEraoHnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('name_scope_multiplication') as scope:\n",
        "    input1 = tf.placeholder(tf.float32, name='input1')\n",
        "    input2 = tf.placeholder(tf.float32, name='input2')\n",
        "    output = tf.multiply(input1, input2, name=scope)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIHfqWoJoHnn",
        "colab_type": "text"
      },
      "source": [
        "A variable declaered as placeholder expects a feed and generate an error if it is not supplied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp7geVGJoHnn",
        "colab_type": "code",
        "outputId": "f50ffe0d-7646-4d7b-940a-90f94d533d60",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([14.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhEJ-OThoHnp",
        "colab_type": "text"
      },
      "source": [
        "You can feed_dict any feedable tensor. **Placeholder is just a way to indicate that something must be fed**. A convenient function called `tf.Graph.is_feedable(tensor)` returns true if tensor is feedable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjT4pAmRoHnq",
        "colab_type": "code",
        "outputId": "6ca0dc20-4ad1-4a5c-c037-ef15e4d695e4",
        "colab": {}
      },
      "source": [
        "init_placeholder = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_placeholder)\n",
        "    print(sess.run([addition], feed_dict={product: 4}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phlDRxzZoHnt",
        "colab_type": "text"
      },
      "source": [
        "The practice of feeding values for some operations is extremely helpful for testing. Feed in dummy values to test parts of a large graph avoids computing those portions of the graph. \n",
        "\n",
        "Remember, never declare an operation at execution time! It will add a new operation to the graph each time. We will illustrate this concept as well as the concept introduced so far with the aid of a tool called TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qh3-cGJoHnt",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3.4 TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q21rww5goHnu",
        "colab_type": "text"
      },
      "source": [
        ">The computations you'll use TensorFlow for - like training a massive deep neural network - can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, we've included a suite of visualization tools called TensorBoard. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it. \n",
        "\n",
        "TensorBoard is a useful tool for visualizing and debugging training of a Nerual Network. It is used to *babysitting* the learning process, display useful information like the graph of the model and to manage experiments. \n",
        "\n",
        "We need to tell TensorFlow to save the graph of the model in order to visualize it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isMjhY8soHnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = tf.summary.FileWriter('temp/graphs', tf.get_default_graph())\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWUSikCFoHnw",
        "colab_type": "text"
      },
      "source": [
        "Then in the current directory (remember to activate your environment) type:\n",
        "\n",
        "`tensorboard --logdir=temp/graphs`\n",
        "\n",
        "A common source of error is to add operations at run time, to the graph. While it is perfectly normal in any computer language, it is a problem in TensorFlow. Let's look at it with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqQDq-OLoHnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(10, name='x')\n",
        "y = tf.Variable(20, name='y')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for _ in range(10):\n",
        "        sess.run(tf.add(x, y)) \n",
        "    writer = tf.summary.FileWriter('temp/graphs', sess.graph)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxLcUXi3oHny",
        "colab_type": "text"
      },
      "source": [
        "Sometimes this is called **lazy loading**. As can be seen we need to defer the creation and initialization of an object until it is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeHeaWWToHny",
        "colab_type": "text"
      },
      "source": [
        "## 3 Building Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w29NwRzoHny",
        "colab_type": "text"
      },
      "source": [
        "Now tensorflow is especially useful to train Machine Learning models. We will briefly sketch the workflow of building simple models. We will switch to more complex models (Neural Networks) in following notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QnwS5SEoHn0",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Linear Regression example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO1sYbHPoHn0",
        "colab_type": "text"
      },
      "source": [
        "The most simple model to build is based on a target variable $y$ that we are trying to predict given input data $x$. We have a set of $x$ and $y$ values that we use to train the model. Suppose that $y$ is a vector with continuous values, we have a regression model that can be described with a simple equation: $f(x) = w^Tx + b$ and $y = f(x) + \\epsilon$, where \n",
        "$f(x)$ is a linear combination of our training data $x$, with a set of weights $w$ and an intercept $b$. The target $y$ is equal to $f(x)$ with added gaussian noise. \n",
        "\n",
        "We implement this simple regression with tensorflow. First we need to create some input data, then we will create the computational graph, we'll train the model and look at the results.\n",
        "\n",
        "Now we define a set of points to used for training and as target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEuZxanloHn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.random.randn(2000, 3)\n",
        "w_real = [0.3, 0.5, 0.1]\n",
        "b_real = -0.2\n",
        "\n",
        "noise = np.random.randn(2000) * 0.1\n",
        "y_real = np.matmul(w_real, data.T) + b_real\n",
        "target = y_real + noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMXbdwoZoHn2",
        "colab_type": "text"
      },
      "source": [
        "**Phase 1:** assemble the graph.\n",
        "\n",
        "*Step 1:* create placeholders for input and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD-zsYAYoHn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.placeholder(tf.float32, shape=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfML7G-zoHn4",
        "colab_type": "text"
      },
      "source": [
        "*Step 2:* create variables for weights and bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB5WcJ4PoHn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_val = tf.random_normal((1, 3), 0, 1)\n",
        "W = tf.get_variable(name='weights', dtype=tf.float32, initializer=init_val)\n",
        "b = tf.get_variable(name='bias', dtype=tf.float32, initializer=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJ41HJpoHn7",
        "colab_type": "text"
      },
      "source": [
        "*Step 3:* define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY0jbb38oHn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_model = tf.matmul(W, X, transpose_b=True) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XVD3y97oHn-",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** How to train such a linear model? There is however a simple closed formula to solve a linear regression model, but we will define a loss function and an optimization operation, that will be inserted into the graph (it will be helpful later on when we will see Neural Networks). **The loss function defines a method to evaluate model performance**. The loss function defines a distance between the predicted values and the target values, and it is used as input to the optimization procedure that finds a set of parameters that minimize the loss function. The most common loss function is the Mean Squared Error (MSE), that finds the squared distance between a set of points and then averages the results over all points. The optimization operation is **gradient descent that iteratively updates the weights in a way that decreases loss over time**. The update rule is **based on the gradient of the loss function**. If the loss is a multivariate function of the weights $F(\\hat w)$, then in the neighborhood of some point $\\hat w_0$, the *steepest* direction of decrease of $F(\\hat w)$ is obtained by moving from $\\hat w_0$ in the direction of the negative gradient of $F$ at $\\hat w_0$. We will give more hints on the gradient descent algorithm and its variants when we will use it with Neural Networks.\n",
        "\n",
        "*Step 4:* define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRTw5OcsoHn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.square(linear_model - y)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeqtEvHjoHoA",
        "colab_type": "text"
      },
      "source": [
        "*Step 5:* define the optimizer and the training operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytbu5mBvoHoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NH05ma3oHoC",
        "colab_type": "text"
      },
      "source": [
        "**Phase 2:** train the model\n",
        "\n",
        "*Step 1: define an init operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm7arDiJoHoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vNWks7IoHoE",
        "colab_type": "text"
      },
      "source": [
        "*Step 2*: run the optimizer with training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iKbn-tGoHoE",
        "colab_type": "code",
        "outputId": "6c3dc618-c9a8-4b4e-f010-e08d2c64c6b1",
        "colab": {}
      },
      "source": [
        "NUM_STEPS = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    tmp_ = sess.run([W, b])\n",
        "    print(0, tmp_[0], tmp_[1])\n",
        "    for step in range(NUM_STEPS):\n",
        "        sess.run(train, {X: data, y: target})\n",
        "        if ((step+1) % 5 == 0):\n",
        "            tmp_ = sess.run([W, b])\n",
        "            print(step+1, tmp_[0], tmp_[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [[ 0.59365594 -0.5348281   0.6166631 ]] 0.0\n",
            "5 [[0.29778492 0.49913204 0.10142566]] -0.19492406\n",
            "10 [[0.29778528 0.49913168 0.10142588]] -0.1949241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2CycjRgoHoJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Classify Digits with Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPcHjqzoHoL",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2.1 The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBsUhRkToHoO",
        "colab_type": "text"
      },
      "source": [
        "We will learn to classify MNIST handwritten digit images into their correct label (0-9). MNIST is a standard dataset hosted on [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/). The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "The importance of classical datasets is twofold. First they are good for people who want to try machine learning techniques while spending minimal efforts on preprocessing and formatting data. Second they are useful for comparing machine learning algorithms, since we know well how they work on these datasets.\n",
        "\n",
        "Each image is 28 pixels by 28 pixels, representing an handwritten number between 0 to 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuD8O5c3oHoR",
        "colab_type": "text"
      },
      "source": [
        "We can interpret this as a big array of numbers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WUkh9JPx_Il",
        "colab_type": "text"
      },
      "source": [
        "<center>  <img src=https://drive.google.com/uc?id=1JJ0PgAwFNjlgAr3ROy8lgilHQW-iTXST \" width=\"800\">  </center> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhVq7L6RoHoU",
        "colab_type": "text"
      },
      "source": [
        "Since each image has 28 by 28 pixels, we get a 28x28 array. We can flatten each array into a 28∗28=784 dimensional vector. Each component of the vector is a value between zero and one describing the intensity of the pixel. Thus, we generally think of MNIST as being a collection of 784-dimensional vectors. Flattening the image may throw away information about the structure and it surely does. There are methods that look directly at the 2D image but will be covered in later tutorials.\n",
        "\n",
        "Now, we load the data and we see how it is organized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oZ11zREoHoU",
        "colab_type": "code",
        "outputId": "2d3153b1-264a-42c2-e944-8ccce6a6cea6",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('./MNIST', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKb48XRUoHoX",
        "colab_type": "text"
      },
      "source": [
        "The dataset is split into three parts, one for training, one for testingand one for validation. Each dataset is an n-dimensional array with shape [number of examples, 784]. Each example is an image with associated a corresponding label, a number between 0 - 9 that represents the digit depicted in the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0drDscz1oHoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# The MNIST images are always 28x28 pixels.\n",
        "IMAGE_SIZE = 28\n",
        "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "796SciBLoHoa",
        "colab_type": "code",
        "outputId": "b7f9e68e-6bfd-4f6f-8190-e96f32cb2838",
        "colab": {}
      },
      "source": [
        "print('train examples: ', mnist.train.num_examples)\n",
        "print('test examples: ', mnist.test.num_examples)\n",
        "print('validation examples: ', mnist.validation.num_examples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train examples:  55000\n",
            "test examples:  10000\n",
            "validation examples:  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRZbkBR4oHoc",
        "colab_type": "text"
      },
      "source": [
        "In order to classify the digits we will use an output layer with 10 units, one for each digits. For this reason our labels are encoded as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case the\n",
        "n-th digit will be represented as a vector which is 1 in the n-th dimension. For example, 3 would be [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]. Consequently, mnist.train.labels is a [55000, 10] array of floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Oi5hOIoHod",
        "colab_type": "code",
        "outputId": "7fdb3021-5ab5-442a-b196-3af6cecd7802",
        "colab": {}
      },
      "source": [
        "print(mnist.train.labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPvDuJGPoHoe",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2.2 The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScYI-dHSoHof",
        "colab_type": "text"
      },
      "source": [
        "We will use a simple linear model for classification, the logistic regression; logistic regression outputs a probability for each class. In particular we will use a softmax classification for the case of multiple classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Ge_ZTcoHof",
        "colab_type": "code",
        "outputId": "ba77f95b-20eb-4dcc-ecd4-105737a01bd3",
        "colab": {}
      },
      "source": [
        "Image('images/logistic_function.png', height=\"500\", width=\"500\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": "500",
              "width": "500"
            }
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXaVO6EMoHog",
        "colab_type": "text"
      },
      "source": [
        "$$\\sigma(z) = \\frac{1}{1+e^{-z}} $$\n",
        "\n",
        "Where the $z$ in previous function has the value of $W^Tx+b$ and the output $c$ of this function is the probability of being in that class that is $P(Y=c \\mid X=x)$, given $x$ parametrized by $W$ and $b$.\n",
        "\n",
        "**Phase 1:**: build the graph.\n",
        "\n",
        "*Step 1:* define two placeholder variables, one for the input $x$ the other for the (true) output $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndl9mRO4oHoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, IMAGE_PIXELS])\n",
        "y = tf.placeholder(tf.int32, shape=[None, NUM_CLASSES])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI_kl5XYoHoi",
        "colab_type": "text"
      },
      "source": [
        "*Step 2:* weights and biases\n",
        "\n",
        "The first variable that must be optimized is called `weights` and is defined here as a TensorFlow variable that must be initialized with zeros and whose shape is `[IMAGE_PIXELS, NUM_CLASSES]`, so it is a 2-dimensional tensor (or matrix) with `IMAGE_PIXELS` rows and `NUM_CLASSES` columns.\n",
        "\n",
        "The second variable that must be optimized is called `biases` and is defined as a 1-dimensional tensor (or vector) of length `NUM_CLASSES`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wPEybNzoHoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = tf.Variable(tf.zeros([IMAGE_PIXELS, NUM_CLASSES]))\n",
        "biases = tf.Variable(tf.zeros([NUM_CLASSES]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhhRvkpioHoj",
        "colab_type": "text"
      },
      "source": [
        "*Step 3: * build the model\n",
        "\n",
        "This simple mathematical model multiplies the images in the placeholder variable `x` with the `weights` and then adds the `biases`.\n",
        "\n",
        "The result is a matrix of shape `[num_images, NUM_CLASSES]` because `x` has shape `[num_images, IMAGE_PIXELS]` and `weights` has shape `[IMAGE_PIXELS, NUM_CLASSES]`, so the multiplication of those two matrices is a matrix with shape `[num_images, NUM_CLASSES]` and then the `biases` vector is added to each row of that matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo8HyQYLoHoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = tf.matmul(x, weights) + biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwRsI3iDoHol",
        "colab_type": "text"
      },
      "source": [
        "Now `logits` is a matrix with `num_images` rows and `num_classes` columns, where **the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.**\n",
        "\n",
        "However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the `logits` matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxAY5k_5oHol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfY_bk1voHon",
        "colab_type": "text"
      },
      "source": [
        "The predicted class can be calculated from the `y_pred` matrix by taking the index of the largest element in each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWS5ef_XoHon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_cls = tf.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2NI2VtMoHoo",
        "colab_type": "text"
      },
      "source": [
        "*Step 3:* define loss function\n",
        "\n",
        "To make the model better at classifying the input images, we must somehow change the variables for `weights` and `biases`. To do this we first need to know how well the model currently performs by comparing the predicted output of the model `y_pred` to the desired output `y`.\n",
        "\n",
        "The softmax is a generalization of the logistic function, it is used to calculate the probability associated to each class and it is usefull in multiclass classification problems. A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities. Here a class is one of the 10 possibile digits. \n",
        "\n",
        "Next we define the cost function, cross entropy in this case. **Cross-entropy gives us a way to express how different two probability distributions are. The more different the distributions p and q are, the more the cross-entropy of p with respect to q will be bigger than the entropy of p**. Similarly, the more different p is from q, the more the cross-entropy of q with respect to p will be bigger than the entropy of q. If the distributions are the same, this difference will be zero. As the difference grows, it will get bigger.\n",
        "\n",
        "The goal of optimization is therefore to minimize the cross-entropy so it gets as close to zero as possible by changing the `weights` and `biases` of the model.\n",
        "\n",
        "TensorFlow has a built-in function for calculating the cross-entropy. Note that it uses the values of the `logits` because it also calculates the softmax internally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-whvA7SAoHoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
        "                                                           labels=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jiVDGxoHoq",
        "colab_type": "text"
      },
      "source": [
        "We have now calculated the cross-entropy for each of the image classifications so we have a measure of how well the model performs on each image individually. But in order to use the cross-entropy to guide the optimization of the model's variables we need a single scalar value, so we simply take the average of the cross-entropy for all the image classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PX4TN1soHoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = tf.reduce_mean(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1NsYQMxoHor",
        "colab_type": "text"
      },
      "source": [
        "*Step 4:* \n",
        "\n",
        "Now that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the basic form of Gradient Descent where the learning rate is set at $0.5$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goxmyiKRoHor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um7l9EWnoHot",
        "colab_type": "text"
      },
      "source": [
        "We need a few more performance measures to display the progress to the user.\n",
        "\n",
        "This is a vector of booleans whether the predicted class equals the true class of each image. \n",
        "\n",
        "This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True becomes 1, and then calculating the average of these numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFuf0TMSoHot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(logits), 1), \n",
        "                              tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GYkP7vWoHou",
        "colab_type": "text"
      },
      "source": [
        "**Phase 2:** train the model\n",
        "\n",
        "*Step 1:* initialize variables\n",
        "\n",
        "There are 50.000 images in the training-set. It takes a long time to calculate the gradient of the model using all these images. We therefore use Stochastic Gradient Descent which only uses a small batch of images in each iteration of the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q43eLLUJoHov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ITERATIONS = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6zRqmZioHow",
        "colab_type": "text"
      },
      "source": [
        "*Step 2:* run optimizer\n",
        "\n",
        "Function for performing a number of optimization iterations so as to gradually improve the `weights` and `biases` of the model. In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGMMfpKYoHox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(NUM_ITERATIONS):\n",
        "    x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
        "\n",
        "    feed_dict_train = {x: x_batch,\n",
        "                       y: y_batch}\n",
        "\n",
        "    session.run(optimizer, feed_dict=feed_dict_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKCbUe74oHoy",
        "colab_type": "text"
      },
      "source": [
        "*Step 3:* verify model accuracy\n",
        "\n",
        "Dict test contains test data that the model has not seen during the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__sddXKoHoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feed_dict_test = {x: mnist.test.images,\n",
        "                  y: mnist.test.labels}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shbOlxiRoHoz",
        "colab_type": "code",
        "outputId": "2aa75099-fd08-461f-e094-2d40240ba768",
        "colab": {}
      },
      "source": [
        "acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
        "    \n",
        "print(\"Accuracy on test set: {0:.1%}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 91.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQHbY1PnoHo1",
        "colab_type": "code",
        "outputId": "bb8d0e2b-7be9-442f-b43f-b3716266d6a7",
        "colab": {}
      },
      "source": [
        "cls_true = np.argmax(mnist.test.labels, axis=1)\n",
        "\n",
        "cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
        "\n",
        "cm = confusion_matrix(y_true=cls_true,\n",
        "                      y_pred=cls_pred)\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 956    0    2    2    0    3   12    3    2    0]\n",
            " [   0 1112    2    2    0    1    4    2   12    0]\n",
            " [   5    9  910   14   13    3   14   14   41    9]\n",
            " [   3    1   20  921    0   19    4   13   17   12]\n",
            " [   1    2    4    1  921    0   11    2    6   34]\n",
            " [   9    4    3   52   12  745   21    8   29    9]\n",
            " [   8    3    5    1   12    6  917    2    4    0]\n",
            " [   2    9   18    9    6    0    0  948    2   34]\n",
            " [   5   10    6   25    9   29   11   14  856    9]\n",
            " [   9    6    2   10   39    5    0   29   10  899]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbWdWYhgoHo2",
        "colab_type": "text"
      },
      "source": [
        "The value at cell $(i, j)$ means the fraction of data points from class $i$ whose classification result is $j$. Ideally, the confusion matrix will be identity matrix (Diagonal cells are $1$ and remaining cells are $0$)."
      ]
    }
  ]
}